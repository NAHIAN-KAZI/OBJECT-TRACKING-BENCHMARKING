# ğŸ¯ MOT Tracking Evaluation Pipeline

This project converts tracking and ground truth JSON files into **MOT Challenge format**, interpolates missing frames, and evaluates tracking performance with per-frame **precision**, **recall**, and **MOTA** metrics.

---

## ğŸ§° Components

### `main_MOTConvert.py`

- Converts `filtered_tracking.json` and `filtered_groundtruth.json` to MOT format.
- Saves outputs as:
  - `mot_output/<video_name>_tracking.txt`
  - `mot_output/<video_name>_gt.txt`
- Optionally interpolates missing frames for smoother evaluation.

### `Evaluation_tracking_Analysis.py`

- Loads the MOT format files.
- Computes frame-by-frame:
  - `True Positives (TP)`
  - `False Positives (FP)`
  - `False Negatives (FN)`
  - `Precision`, `Recall`, `MOTA`
- Saves:
  - ğŸ“Š `framewise_summary.csv`  
  - ğŸ“„ `framewise_summary.json`  
  - ğŸ–¼ï¸ `metrics_over_time.png`

---

## ğŸš€ How to Use

1. **Convert to MOT Format**:
   ```bash
   python main_MOTConvert.py
   ```
2. **Run Evaluation**:
   ```bash
   python Evaluation_tracking_Analysis.py
   ```
## ğŸ“‚ Output Directory Structure
```bash
   .
â”œâ”€â”€ filtered_tracking.json
â”œâ”€â”€ filtered_groundtruth.json
â”œâ”€â”€ mot_output/
â”‚   â”œâ”€â”€ <video>_tracking.txt
â”‚   â”œâ”€â”€ <video>_gt.txt
â”‚   â”œâ”€â”€ interpolated_tracking.txt
â”‚   â””â”€â”€ interpolated_gt.txt
â”œâ”€â”€ mot_analysis_output/
â”‚   â”œâ”€â”€ framewise_summary.csv
â”‚   â”œâ”€â”€ framewise_summary.json
â”‚   â””â”€â”€ metrics_over_time.png
```

## ğŸ§  Notes

- Class IDs are mapped: car = 1, truck = 2

- 3D coordinates (x3d, y3d) are unused: set as -1

- Interpolation improves evaluation by filling gaps between tracked frames
